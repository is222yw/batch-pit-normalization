{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from modules.BatchPitNormalization import BatchPitNorm1d\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.028163064833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_408606/1941237738.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_df['Gender_Encoded'] = le_gender.fit_transform(X_df['Gender'])\n",
      "/tmp/ipykernel_408606/1941237738.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_df['Age_Encoded'] = le_age.fit_transform(X_df['Age'])\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "infrared_thermography_temperature = fetch_ucirepo(id=925) \n",
    "\n",
    "\n",
    "X_df = infrared_thermography_temperature.data.features \n",
    "y_df = infrared_thermography_temperature.data.targets \n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "le_age = LabelEncoder()\n",
    "le_ethnicity = LabelEncoder()\n",
    "\n",
    "X_df['Gender_Encoded'] = le_gender.fit_transform(X_df['Gender'])\n",
    "X_df['Age_Encoded'] = le_age.fit_transform(X_df['Age'])\n",
    "X_df['Ethnicity_Encoded'] = le_ethnicity.fit_transform(X_df['Ethnicity'])\n",
    "\n",
    "X_df = X_df.drop('Gender', axis=1)\n",
    "X_df = X_df.drop('Age', axis=1)\n",
    "X_df = X_df.drop('Ethnicity', axis=1)\n",
    "\n",
    "\n",
    "X = X_df.values\n",
    "Y = y_df.values[:, 1].reshape(-1, 1)\n",
    "\n",
    "\n",
    "Y=Y[~np.isnan(X).any(axis=1)]\n",
    "X=X[~np.isnan(X).any(axis=1)]\n",
    "\n",
    "print(np.mean(Y))\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, train_size = 0.7, shuffle = True)\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalerY = StandardScaler()\n",
    "# scale\n",
    "scaler_x = scalerX.fit(X_train_raw)\n",
    "scaler_y = scalerY.fit(y_train_raw)\n",
    "\n",
    "X_train = scaler_x.transform(X_train_raw)\n",
    "X_test = scaler_x.transform(X_test_raw)\n",
    "\n",
    "\n",
    "y_train = scaler_y.transform(y_train_raw)\n",
    "y_test = scaler_y.transform(y_test_raw)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device=device).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without bn\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with bn on first\n",
    "class NeuralNetwork_bn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork_bn, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "class NeuralNetwork_bn2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork_bn2, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with batch pit\n",
    "class NeuralNetwork_pit(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes,num_pit_samples,take_num_samples_when_full,normal_backtransform,trainable_bandwidth):\n",
    "        super(NeuralNetwork_pit, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "class NeuralNetwork_pit2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes,num_pit_samples,take_num_samples_when_full,normal_backtransform,trainable_bandwidth):\n",
    "        super(NeuralNetwork_pit2, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "class NeuralNetwork_pit3(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes,num_pit_samples,take_num_samples_when_full,normal_backtransform,trainable_bandwidth):\n",
    "        super(NeuralNetwork_pit3, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            BatchPitNorm1d(num_features=hidden_size,num_pit_samples=num_pit_samples,dev=device,take_num_samples_when_full=take_num_samples_when_full,normal_backtransform=normal_backtransform,trainable_bandwidths=trainable_bandwidth),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(X,Y,grid_search: bool=False):\n",
    "    if grid_search:\n",
    "        X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, train_size = 0.7, random_state=1)\n",
    "    else:\n",
    "        X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, train_size = 0.7, shuffle = True)\n",
    "    #scalers\n",
    "    scaler_x = StandardScaler().fit(X_train_raw)\n",
    "    scaler_y = StandardScaler().fit(y_train_raw)\n",
    "\n",
    "    #scale data\n",
    "    X_train = scaler_x.transform(X_train_raw)\n",
    "    X_test = scaler_x.transform(X_test_raw)\n",
    "    y_train = scaler_y.transform(y_train_raw)\n",
    "    y_test = scaler_y.transform(y_test_raw)\n",
    "    #make tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler_x, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,root_mean_squared_error\n",
    "def train_model(model,grid_search: bool=False):\n",
    "    X_train,y_train,X_test,y_test,scaler_x,scaler_y = get_train_test_data(X,Y,grid_search)\n",
    "    \n",
    "    input_size = 8\n",
    "    hidden_size = 32\n",
    "    num_classes = 1\n",
    "    learning_rate = 0.001 \n",
    "    n_epochs = 30 \n",
    "    batch_size = 64\n",
    "    model.to(device)\n",
    "    model.cuda()\n",
    "    lossFunction = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=batch_size)\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        for Xbatch, ybatch in loader:\n",
    "            \n",
    "            y_pred = model(Xbatch)\n",
    "            loss = lossFunction(y_pred, ybatch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    y_pred_eval = model(X_test)\n",
    "    y_pred_eval = y_pred_eval.detach().cpu().numpy()\n",
    "    y_pred_scaled = scaler_y.inverse_transform(y_pred_eval)\n",
    "    y_test_eval = y_test.detach().cpu().numpy()\n",
    "    y_test_scaled = scaler_y.inverse_transform(y_test_eval)\n",
    "    r2 = r2_score(y_test_scaled,y_pred_scaled)\n",
    "    mae = mean_absolute_error(y_test_scaled,y_pred_scaled)\n",
    "    rmse = root_mean_squared_error(y_test_scaled,y_pred_scaled)\n",
    "    #print(\"R2-score: \",r2)\n",
    "    #print(\"MAE: \", mae)\n",
    "    #print(\"RMSE: \", rmse)\n",
    "    return r2, mae,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18723373, (50, 0, True, True)] (50, 0, True, True) 0.18723373\n",
      "[0.18723373, (50, 0, True, True)] (50, 0, True, False) 0.20371608\n",
      "[0.18723373, (50, 0, True, True)] (50, 0, False, True) 0.20755868\n",
      "[0.18723373, (50, 0, True, True)] (50, 0, False, False) 0.22728047\n",
      "[0.18723373, (50, 0, True, True)] (50, 1, True, True) 0.19017674\n",
      "[0.18723373, (50, 0, True, True)] (50, 1, True, False) 0.22089775\n",
      "[0.18723373, (50, 0, True, True)] (50, 1, False, True) 0.22905916\n",
      "[0.18723373, (50, 0, True, True)] (50, 1, False, False) 0.23737912\n",
      "[0.18723373, (50, 0, True, True)] (50, 2, True, True) 0.2116947\n",
      "[0.18723373, (50, 0, True, True)] (50, 2, True, False) 0.1961536\n",
      "[0.18723373, (50, 0, True, True)] (50, 2, False, True) 0.23323366\n",
      "[0.18723373, (50, 0, True, True)] (50, 2, False, False) 0.24001305\n",
      "[0.18723373, (50, 0, True, True)] (50, 3, True, True) 0.20962101\n",
      "[0.18723373, (50, 0, True, True)] (50, 3, True, False) 0.2148238\n",
      "[0.18723373, (50, 0, True, True)] (50, 3, False, True) 0.23517145\n",
      "[0.18723373, (50, 0, True, True)] (50, 3, False, False) 0.26420695\n",
      "[0.18723373, (50, 0, True, True)] (50, 5, True, True) 0.194882\n",
      "[0.18723373, (50, 0, True, True)] (50, 5, True, False) 0.25032142\n",
      "[0.18723373, (50, 0, True, True)] (50, 5, False, True) 0.22982503\n",
      "[0.18723373, (50, 0, True, True)] (50, 5, False, False) 0.3009034\n",
      "[0.18130381, (50, 10, True, True)] (50, 10, True, True) 0.18130381\n",
      "[0.18130381, (50, 10, True, True)] (50, 10, True, False) 0.2675318\n",
      "[0.18130381, (50, 10, True, True)] (50, 10, False, True) 0.21660548\n",
      "[0.18130381, (50, 10, True, True)] (50, 10, False, False) 0.285702\n",
      "[0.18130381, (50, 10, True, True)] (100, 0, True, True) 0.18522872\n",
      "[0.18130381, (50, 10, True, True)] (100, 0, True, False) 0.21577269\n",
      "[0.18130381, (50, 10, True, True)] (100, 0, False, True) 0.20729658\n",
      "[0.18130381, (50, 10, True, True)] (100, 0, False, False) 0.21520941\n",
      "[0.18130381, (50, 10, True, True)] (100, 1, True, True) 0.1946662\n",
      "[0.18130381, (50, 10, True, True)] (100, 1, True, False) 0.2006614\n",
      "[0.18130381, (50, 10, True, True)] (100, 1, False, True) 0.2085691\n",
      "[0.18130381, (50, 10, True, True)] (100, 1, False, False) 0.23681574\n",
      "[0.18130381, (50, 10, True, True)] (100, 2, True, True) 0.19074735\n",
      "[0.18130381, (50, 10, True, True)] (100, 2, True, False) 0.21345113\n",
      "[0.18130381, (50, 10, True, True)] (100, 2, False, True) 0.20311952\n",
      "[0.18130381, (50, 10, True, True)] (100, 2, False, False) 0.23362687\n",
      "[0.18130381, (50, 10, True, True)] (100, 3, True, True) 0.19914714\n",
      "[0.18130381, (50, 10, True, True)] (100, 3, True, False) 0.20693648\n",
      "[0.18130381, (50, 10, True, True)] (100, 3, False, True) 0.25688058\n",
      "[0.18130381, (50, 10, True, True)] (100, 3, False, False) 0.24088347\n",
      "[0.18130381, (50, 10, True, True)] (100, 5, True, True) 0.19631447\n",
      "[0.18130381, (50, 10, True, True)] (100, 5, True, False) 0.2047568\n",
      "[0.18130381, (50, 10, True, True)] (100, 5, False, True) 0.21475025\n",
      "[0.18130381, (50, 10, True, True)] (100, 5, False, False) 0.31720224\n",
      "[0.18130381, (50, 10, True, True)] (100, 10, True, True) 0.2194724\n",
      "[0.18130381, (50, 10, True, True)] (100, 10, True, False) 0.23109673\n",
      "[0.18130381, (50, 10, True, True)] (100, 10, False, True) 0.21510619\n",
      "[0.18130381, (50, 10, True, True)] (100, 10, False, False) 0.2753199\n",
      "[0.17878887, (150, 0, True, True)] (150, 0, True, True) 0.17878887\n",
      "[0.17878887, (150, 0, True, True)] (150, 0, True, False) 0.20885824\n",
      "[0.17878887, (150, 0, True, True)] (150, 0, False, True) 0.19985405\n",
      "[0.17878887, (150, 0, True, True)] (150, 0, False, False) 0.22964422\n",
      "[0.17878887, (150, 0, True, True)] (150, 1, True, True) 0.18777123\n",
      "[0.17878887, (150, 0, True, True)] (150, 1, True, False) 0.19802319\n",
      "[0.17878887, (150, 0, True, True)] (150, 1, False, True) 0.2127716\n",
      "[0.17878887, (150, 0, True, True)] (150, 1, False, False) 0.22969075\n",
      "[0.17878887, (150, 0, True, True)] (150, 2, True, True) 0.19558972\n",
      "[0.17878887, (150, 0, True, True)] (150, 2, True, False) 0.19923078\n",
      "[0.17878887, (150, 0, True, True)] (150, 2, False, True) 0.21885636\n",
      "[0.17878887, (150, 0, True, True)] (150, 2, False, False) 0.23195852\n",
      "[0.17878887, (150, 0, True, True)] (150, 3, True, True) 0.1911634\n",
      "[0.17878887, (150, 0, True, True)] (150, 3, True, False) 0.20372061\n",
      "[0.17878887, (150, 0, True, True)] (150, 3, False, True) 0.20543246\n",
      "[0.17878887, (150, 0, True, True)] (150, 3, False, False) 0.24936269\n",
      "[0.17878887, (150, 0, True, True)] (150, 5, True, True) 0.18862034\n",
      "[0.17878887, (150, 0, True, True)] (150, 5, True, False) 0.21352586\n",
      "[0.17878887, (150, 0, True, True)] (150, 5, False, True) 0.21072443\n",
      "[0.17878887, (150, 0, True, True)] (150, 5, False, False) 0.28472328\n",
      "[0.17878887, (150, 0, True, True)] (150, 10, True, True) 0.196238\n",
      "[0.17878887, (150, 0, True, True)] (150, 10, True, False) 0.21101713\n",
      "[0.17878887, (150, 0, True, True)] (150, 10, False, True) 0.21679229\n",
      "[0.17878887, (150, 0, True, True)] (150, 10, False, False) 0.29516876\n",
      "[0.17878887, (150, 0, True, True)] (250, 0, True, True) 0.1793952\n",
      "[0.17878887, (150, 0, True, True)] (250, 0, True, False) 0.20734592\n",
      "[0.17878887, (150, 0, True, True)] (250, 0, False, True) 0.20418221\n",
      "[0.17878887, (150, 0, True, True)] (250, 0, False, False) 0.2253448\n",
      "[0.17878887, (150, 0, True, True)] (250, 1, True, True) 0.18028186\n",
      "[0.17878887, (150, 0, True, True)] (250, 1, True, False) 0.20320702\n",
      "[0.17878887, (150, 0, True, True)] (250, 1, False, True) 0.21913396\n",
      "[0.17878887, (150, 0, True, True)] (250, 1, False, False) 0.2341\n",
      "[0.17878887, (150, 0, True, True)] (250, 2, True, True) 0.1898531\n",
      "[0.17878887, (150, 0, True, True)] (250, 2, True, False) 0.23819195\n",
      "[0.17878887, (150, 0, True, True)] (250, 2, False, True) 0.20649052\n",
      "[0.17878887, (150, 0, True, True)] (250, 2, False, False) 0.2217397\n",
      "[0.17878887, (150, 0, True, True)] (250, 3, True, True) 0.19530232\n",
      "[0.17878887, (150, 0, True, True)] (250, 3, True, False) 0.2039376\n",
      "[0.17878887, (150, 0, True, True)] (250, 3, False, True) 0.21314444\n",
      "[0.17878887, (150, 0, True, True)] (250, 3, False, False) 0.21850301\n",
      "[0.17878887, (150, 0, True, True)] (250, 5, True, True) 0.19554573\n",
      "[0.17878887, (150, 0, True, True)] (250, 5, True, False) 0.20951444\n",
      "[0.17878887, (150, 0, True, True)] (250, 5, False, True) 0.20756726\n",
      "[0.17878887, (150, 0, True, True)] (250, 5, False, False) 0.2325141\n",
      "[0.17878887, (150, 0, True, True)] (250, 10, True, True) 0.1979046\n",
      "[0.17878887, (150, 0, True, True)] (250, 10, True, False) 0.21320198\n",
      "[0.17878887, (150, 0, True, True)] (250, 10, False, True) 0.21358441\n",
      "[0.17878887, (150, 0, True, True)] (250, 10, False, False) 0.25763\n",
      "[0.17878887, (150, 0, True, True)] (500, 0, True, True) 0.184198\n",
      "[0.17878887, (150, 0, True, True)] (500, 0, True, False) 0.21899296\n",
      "[0.17878887, (150, 0, True, True)] (500, 0, False, True) 0.20405234\n",
      "[0.17878887, (150, 0, True, True)] (500, 0, False, False) 0.22405557\n",
      "[0.17878887, (150, 0, True, True)] (500, 1, True, True) 0.1843731\n",
      "[0.17878887, (150, 0, True, True)] (500, 1, True, False) 0.2016856\n",
      "[0.17878887, (150, 0, True, True)] (500, 1, False, True) 0.20399272\n",
      "[0.17878887, (150, 0, True, True)] (500, 1, False, False) 0.22386155\n",
      "[0.17878887, (150, 0, True, True)] (500, 2, True, True) 0.18919727\n",
      "[0.17878887, (150, 0, True, True)] (500, 2, True, False) 0.21576162\n",
      "[0.17878887, (150, 0, True, True)] (500, 2, False, True) 0.23021321\n",
      "[0.17878887, (150, 0, True, True)] (500, 2, False, False) 0.22023718\n",
      "[0.17878887, (150, 0, True, True)] (500, 3, True, True) 0.18226327\n",
      "[0.17878887, (150, 0, True, True)] (500, 3, True, False) 0.21339391\n",
      "[0.17878887, (150, 0, True, True)] (500, 3, False, True) 0.21649499\n",
      "[0.17878887, (150, 0, True, True)] (500, 3, False, False) 0.21701072\n",
      "[0.17878887, (150, 0, True, True)] (500, 5, True, True) 0.18513137\n",
      "[0.17878887, (150, 0, True, True)] (500, 5, True, False) 0.2106757\n",
      "[0.17878887, (150, 0, True, True)] (500, 5, False, True) 0.20155247\n",
      "[0.17878887, (150, 0, True, True)] (500, 5, False, False) 0.22265555\n",
      "[0.17878887, (150, 0, True, True)] (500, 10, True, True) 0.18881361\n",
      "[0.17878887, (150, 0, True, True)] (500, 10, True, False) 0.21559846\n",
      "[0.17878887, (150, 0, True, True)] (500, 10, False, True) 0.21048617\n",
      "[0.17878887, (150, 0, True, True)] (500, 10, False, False) 0.22730693\n",
      "[0.17878887, (150, 0, True, True)] (1000, 0, True, True) 0.18019938\n",
      "[0.17878887, (150, 0, True, True)] (1000, 0, True, False) 0.21863605\n",
      "[0.17878887, (150, 0, True, True)] (1000, 0, False, True) 0.22209965\n",
      "[0.17878887, (150, 0, True, True)] (1000, 0, False, False) 0.2264641\n",
      "[0.17878887, (150, 0, True, True)] (1000, 1, True, True) 0.18145284\n",
      "[0.17878887, (150, 0, True, True)] (1000, 1, True, False) 0.20211598\n",
      "[0.17878887, (150, 0, True, True)] (1000, 1, False, True) 0.2026483\n",
      "[0.17878887, (150, 0, True, True)] (1000, 1, False, False) 0.21831842\n",
      "[0.17878887, (150, 0, True, True)] (1000, 2, True, True) 0.18297751\n",
      "[0.17878887, (150, 0, True, True)] (1000, 2, True, False) 0.21751988\n",
      "[0.17878887, (150, 0, True, True)] (1000, 2, False, True) 0.20574743\n",
      "[0.17878887, (150, 0, True, True)] (1000, 2, False, False) 0.21449672\n",
      "[0.17878887, (150, 0, True, True)] (1000, 3, True, True) 0.1869823\n",
      "[0.17878887, (150, 0, True, True)] (1000, 3, True, False) 0.20371538\n",
      "[0.17878887, (150, 0, True, True)] (1000, 3, False, True) 0.20027642\n",
      "[0.17878887, (150, 0, True, True)] (1000, 3, False, False) 0.21525599\n",
      "[0.17878887, (150, 0, True, True)] (1000, 5, True, True) 0.18238239\n",
      "[0.17878887, (150, 0, True, True)] (1000, 5, True, False) 0.2046452\n",
      "[0.17878887, (150, 0, True, True)] (1000, 5, False, True) 0.20383361\n",
      "[0.17878887, (150, 0, True, True)] (1000, 5, False, False) 0.21723838\n",
      "[0.17878887, (150, 0, True, True)] (1000, 10, True, True) 0.18677855\n",
      "[0.17878887, (150, 0, True, True)] (1000, 10, True, False) 0.21629244\n",
      "[0.17878887, (150, 0, True, True)] (1000, 10, False, True) 0.209493\n",
      "[0.17878887, (150, 0, True, True)] (1000, 10, False, False) 0.23010136\n",
      "best!!!  [0.17878887, (150, 0, True, True)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def grid_search():\n",
    "    from itertools import product\n",
    "    # Hyperparameter grid\n",
    "    param_grid = {\n",
    "        'num_pit_samples': [50, 100, 150, 250, 500, 1000],\n",
    "        'take_num_samples_when_full': [0, 1, 2, 3, 5, 10],\n",
    "        'normal_backtransform': [True, False],\n",
    "        'trainable_bandwidths': [True, False]\n",
    "    }\n",
    "    results = np.array((\"mae\",\"r2\",\"num_pit_samples\",\"take_num_samples_when_full\",\"normal_backtransform\",\"trainable_bandwidth\",\"model_id\"))\n",
    "    model_id = \"model 3\"\n",
    "    hidden_size = 32\n",
    "    input_size = 33\n",
    "    num_classes = 1\n",
    "    best_params = []\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    "        model = NeuralNetwork_pit3(input_size=input_size,\n",
    "                                hidden_size=hidden_size,\n",
    "                                num_classes=num_classes,\n",
    "                                num_pit_samples=num_pit_samples,\n",
    "                                normal_backtransform=normal_backtransform,\n",
    "                                take_num_samples_when_full=take_num_samples_when_full,\n",
    "                                trainable_bandwidth=trainable_bandwidths\n",
    "                                )\n",
    "        # train model\n",
    "        try:\n",
    "            r2, mae,rmse = train_model(model,grid_search=True)\n",
    "            \n",
    "            if best_params == []:\n",
    "                best_params.append(mae)\n",
    "                best_params.append(params)\n",
    "            elif mae < best_params[0]:\n",
    "                best_params[0] = mae\n",
    "                best_params[1] = params\n",
    "\n",
    "            grid_res = np.array((mae,r2, params[0],params[1],params[2],params[3],model_id))\n",
    "            results = np.vstack((results,grid_res))\n",
    "            print(best_params, params, mae)\n",
    "            #print(results)\n",
    "        except:\n",
    "            return results\n",
    "    print(\"best!!! \", best_params)\n",
    "    return results\n",
    "\n",
    "results_grid = grid_search()\n",
    "\n",
    "# convert array into dataframe \n",
    "DF = pd.DataFrame(results_grid) \n",
    "  \n",
    "# save the dataframe as a csv file \n",
    "DF.to_csv(\"temp_model3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
