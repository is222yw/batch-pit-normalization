{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression about the total power out of the large wave farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  149\n",
      "Number of datapoints:  36043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from bpitnorm.modules.BatchPitNormalization import BatchPitNorm1d\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data = np.genfromtxt(\"../Data/waveEnergy.csv\", delimiter=\",\", skip_header=1)\n",
    "data = data[~(np.isnan(data)).any(axis=1)]\n",
    "data = data[~(np.isinf(data)).any(axis=1)]\n",
    "print(\"Number of features: \", data.shape[1])\n",
    "print(\"Number of datapoints: \", data.shape[0])\n",
    "\n",
    "def data_split(data, grid_search: bool=False):\n",
    "  if grid_search:\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(data[:, :-1], data[:, -1], test_size=0.2, random_state=0)\n",
    "  else:\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "  y_train_raw = y_train_raw.reshape(-1, 1)\n",
    "  y_test_raw = y_test_raw.reshape(-1, 1)\n",
    "\n",
    "  scaler1 = StandardScaler()\n",
    "  scaler_x = scaler1.fit(X_train_raw)\n",
    "  X_train = scaler_x.transform(X_train_raw)\n",
    "  X_test = scaler_x.transform(X_test_raw)\n",
    "\n",
    "  scaler2 = StandardScaler()\n",
    "  scaler_y = scaler2.fit(y_train_raw)\n",
    "  y_train = scaler_y.transform(y_train_raw)\n",
    "  y_test = scaler_y.transform(y_test_raw)\n",
    "\n",
    "  X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "  y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "  X_test = torch.tensor(X_test, dtype=torch.float32).to(device=device)\n",
    "  y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device=device)\n",
    "  return X_train, y_train, X_test, y_test, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def train_model(model, loops, grid_search: bool=False):\n",
    "    model.to(device=device)\n",
    "    r2score_lst = np.zeros(loops)\n",
    "    meanAbsoluteError_lst = np.zeros(loops)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    for i in range(loops):\n",
    "        X_train, y_train, X_test, y_test, scaler_y = data_split(data, grid_search)\n",
    "        loss_fn = nn.MSELoss().to(device=device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=48, shuffle=True)\n",
    "        n_epochs = 30\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device=device)\n",
    "                y_batch = y_batch.to(device=device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        y_test_inverse = scaler_y.inverse_transform(y_test.cpu())\n",
    "        y_pred = model(X_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "        r2score = r2_score(y_test_inverse, y_pred)\n",
    "        r2score_lst[i] = r2score\n",
    "        meanAbsoluteError = mean_absolute_error(y_test_inverse, y_pred)\n",
    "        meanAbsoluteError_lst[i] = meanAbsoluteError\n",
    "    return r2score_lst, meanAbsoluteError_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "  'num_pit_samples': [50, 100, 150, 250, 500, 1000],\n",
    "  'take_num_samples_when_full': [0, 1, 2, 3, 5, 10],\n",
    "  'normal_backtransform': [True, False],\n",
    "  'trainable_bandwidths': [True, False]\n",
    "}\n",
    "\n",
    "best_mae_4 = np.inf\n",
    "best_params_4 = None\n",
    "best_mae_5 = np.inf\n",
    "best_params_5 = None\n",
    "best_mae_6 = np.inf\n",
    "best_params_6 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model4\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m   r2_4, mae_4 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(mae_4) \u001b[38;5;241m<\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(best_mae_4):\n\u001b[1;32m     22\u001b[0m     best_mae_4 \u001b[38;5;241m=\u001b[39m mae_4\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, loops, grid_search)\u001b[0m\n\u001b[1;32m     23\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/rd/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rd/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model4 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    BatchPitNorm1d(num_features=80, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model4.to(device=device)\n",
    "  try:\n",
    "    r2_4, mae_4 = train_model(model4, 1, True)\n",
    "    if np.mean(mae_4) < np.mean(best_mae_4):\n",
    "      best_mae_4 = mae_4\n",
    "      best_r2_4 = r2_4\n",
    "      best_params_4 = params\n",
    "\n",
    "    values = np.array([np.mean(mae_4), np.mean(r2_4), num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 4\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy4.csv\", index=False)\n",
    "    break\n",
    "\n",
    "print(f\"Model 4: Best params: {best_params_4} with MAE: {np.mean(best_mae_4)}, R2-score: {np.mean(best_r2_4)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=1000, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 4.08 GiB is allocated by PyTorch, and 2.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Model 5: Best params: (150, 0, True, True) with MAE: 2736.671858644456, R2-score: 0.9989245252800507\n"
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model5 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    BatchPitNorm1d(num_features=50, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(80),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model5.to(device=device)\n",
    "  \n",
    "  try:\n",
    "    r2_5, mae_5 = train_model(model5, 1, True)\n",
    "    if np.mean(mae_5) < np.mean(best_mae_5):\n",
    "      best_mae_5 = mae_5\n",
    "      best_r2_5 = r2_5\n",
    "      best_params_5 = params\n",
    "    values = np.array([np.mean(mae_5), np.mean(r2_5), num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 5\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy5.csv\", index=False)\n",
    "    break\n",
    "  \n",
    "print(f\"Model 5: Best params: {best_params_5} with MAE: {np.mean(best_mae_5)}, R2-score: {np.mean(best_r2_5)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "mat1 and mat2 shapes cannot be multiplied (64x148 and 8x100)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_r2_6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy6.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 6: Best params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params_6\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(best_mae_6)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mbest_r2_6\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n\u001b[1;32m     38\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy6.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_r2_6' is not defined"
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model6 = nn.Sequential(\n",
    "    nn.Linear(8, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    BatchPitNorm1d(num_features=10, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model6.to(device=device)\n",
    "  \n",
    "  try:\n",
    "    mae_6, r2_6 = train_model(model6, 1, True)\n",
    "    if np.mean(mae_6) < np.mean(best_mae_6):\n",
    "      best_mae_6 = mae_6\n",
    "      best_r2_6 = r2_6\n",
    "      best_params_6 = params\n",
    "\n",
    "    values = np.array([mae_6, r2_6, num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 6\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy6.csv\", index=False)\n",
    "    break\n",
    "print(f\"Model 6: Best params: {best_params_6} with accuracy: {np.mean(best_mae_6)}, F1-score: {np.mean(best_r2_6)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1))\n",
    "model1.to(device=device)\n",
    "\n",
    "r2Score1, MAE1 = train_model(model1, 5)\n",
    "plt.boxplot(r2Score1, labels=[\"Model 1\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean of all total energies: {np.mean(data[:, -1])}\")\n",
    "plt.boxplot(MAE1, labels=[\"Model 1\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1))\n",
    "model2.to(device=device)\n",
    "\n",
    "r2Score2, MAE2 = train_model(model2, 5)\n",
    "plt.boxplot(r2Score2, labels=[\"Model 2\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE2, labels=[\"Model 2\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    BatchPitNorm1d(num_features=80, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model4.to(device=device)\n",
    "\n",
    "r2Score4, MAE4 = train_model(model4, 5)\n",
    "plt.boxplot(r2Score4, labels=[\"Model 4\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE4, labels=[\"Model 4\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    BatchPitNorm1d(num_features=50, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(80),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model5.to(device=device)\n",
    "\n",
    "r2Score5, MAE5 = train_model(model5, 5)\n",
    "plt.boxplot(r2Score5, labels=[\"Model 5\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE5, labels=[\"Model 5\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    BatchPitNorm1d(num_features=10, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model6.to(device=device)\n",
    "\n",
    "r2Score6, MAE6 = train_model(model6, 5)\n",
    "plt.boxplot(r2Score6, labels=[\"Model 6\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE6, labels=[\"Model 6\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([r2Score1, r2Score2, r2Score4, r2Score5, r2Score6], labels=[\"No bn/pit\", \"No pit\", \"Model 3\", \"Model 4\", \"model 6\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot([MAE1, MAE2, MAE4, MAE5, MAE6], labels=[\"No bn/pit\", \"No pit\", \"Model 4\", \"Model 5\", \"model 6\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
