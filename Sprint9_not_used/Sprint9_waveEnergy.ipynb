{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression about the total power out of the large wave farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  149\n",
      "Number of datapoints:  36043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from bpitnorm.modules.BatchPitNormalization import BatchPitNorm1d\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data = np.genfromtxt(\"../Data/waveEnergy.csv\", delimiter=\",\", skip_header=1)\n",
    "data = data[~(np.isnan(data)).any(axis=1)]\n",
    "data = data[~(np.isinf(data)).any(axis=1)]\n",
    "print(\"Number of features: \", data.shape[1])\n",
    "print(\"Number of datapoints: \", data.shape[0])\n",
    "\n",
    "def data_split(data, grid_search: bool=False):\n",
    "  if grid_search:\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(data[:, :-1], data[:, -1], test_size=0.2, random_state=0)\n",
    "  else:\n",
    "    X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "  y_train_raw = y_train_raw.reshape(-1, 1)\n",
    "  y_test_raw = y_test_raw.reshape(-1, 1)\n",
    "\n",
    "  scaler1 = StandardScaler()\n",
    "  scaler_x = scaler1.fit(X_train_raw)\n",
    "  X_train = scaler_x.transform(X_train_raw)\n",
    "  X_test = scaler_x.transform(X_test_raw)\n",
    "\n",
    "  scaler2 = StandardScaler()\n",
    "  scaler_y = scaler2.fit(y_train_raw)\n",
    "  y_train = scaler_y.transform(y_train_raw)\n",
    "  y_test = scaler_y.transform(y_test_raw)\n",
    "\n",
    "  X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "  y_train = torch.tensor(y_train, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "  X_test = torch.tensor(X_test, dtype=torch.float32).to(device=device)\n",
    "  y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device=device)\n",
    "  return X_train, y_train, X_test, y_test, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def train_model(model, loops, grid_search: bool=False):\n",
    "    model.to(device=device)\n",
    "    r2score_lst = np.zeros(loops)\n",
    "    meanAbsoluteError_lst = np.zeros(loops)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    for i in range(loops):\n",
    "        X_train, y_train, X_test, y_test, scaler_y = data_split(data, grid_search)\n",
    "        loss_fn = nn.MSELoss().to(device=device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=12, shuffle=True)\n",
    "        n_epochs = 30\n",
    "        for epoch in range(n_epochs):\n",
    "            model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device=device)\n",
    "                y_batch = y_batch.to(device=device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        model.eval()\n",
    "        y_test_inverse = scaler_y.inverse_transform(y_test.cpu())\n",
    "        y_pred = model(X_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "        r2score = r2_score(y_test_inverse, y_pred)\n",
    "        r2score_lst[i] = r2score\n",
    "        meanAbsoluteError = mean_absolute_error(y_test_inverse, y_pred)\n",
    "        meanAbsoluteError_lst[i] = meanAbsoluteError\n",
    "    return r2score_lst, meanAbsoluteError_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_294557/1724512681.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "  'num_pit_samples': [1000, 500, 250, 150, 100, 50], # [50, 100, 150, 250, 500, 1000],\n",
    "  'take_num_samples_when_full': [0, 1, 2, 3, 5, 10],\n",
    "  'normal_backtransform': [True, False],\n",
    "  'trainable_bandwidths': [True, False]\n",
    "}\n",
    "\n",
    "best_mae_4 = np.inf\n",
    "best_params_4 = None\n",
    "best_mae_5 = np.inf\n",
    "best_params_5 = None\n",
    "best_mae_6 = np.inf\n",
    "best_params_6 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=1000, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacity of 7.92 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 6.61 GiB memory in use. Of the allocated memory 6.49 GiB is allocated by PyTorch, and 16.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_r2_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 4: Best params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params_4\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(best_mae_4)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, R2-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mbest_r2_4\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n\u001b[1;32m     36\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy4.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_r2_4' is not defined"
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model4 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    BatchPitNorm1d(num_features=80, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model4.to(device=device)\n",
    "  try:\n",
    "    r2_4, mae_4 = train_model(model4, 1, True)\n",
    "    if np.mean(mae_4) < np.mean(best_mae_4):\n",
    "      best_mae_4 = mae_4\n",
    "      best_r2_4 = r2_4\n",
    "      best_params_4 = params\n",
    "\n",
    "    values = np.array([np.mean(mae_4), np.mean(r2_4), num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 4\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy4.csv\", index=False)\n",
    "    break\n",
    "\n",
    "print(f\"Model 4: Best params: {best_params_4} with MAE: {np.mean(best_mae_4)}, R2-score: {np.mean(best_r2_4)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy4.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=50, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=100, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=150, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=250, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=0, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=1, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=2, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=3, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=5, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=True, trainable_bandwidths=False\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=True\n",
      "num_pit_samples=500, take_num_samples_when_full=10, normal_backtransform=False, trainable_bandwidths=False\n",
      "num_pit_samples=1000, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "CUDA out of memory. Tried to allocate 1.34 GiB. GPU 0 has a total capacity of 7.92 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 4.08 GiB is allocated by PyTorch, and 2.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Model 5: Best params: (150, 0, True, True) with MAE: 2736.671858644456, R2-score: 0.9989245252800507\n"
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model5 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    BatchPitNorm1d(num_features=50, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(80),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model5.to(device=device)\n",
    "  \n",
    "  try:\n",
    "    r2_5, mae_5 = train_model(model5, 1, True)\n",
    "    if np.mean(mae_5) < np.mean(best_mae_5):\n",
    "      best_mae_5 = mae_5\n",
    "      best_r2_5 = r2_5\n",
    "      best_params_5 = params\n",
    "    values = np.array([np.mean(mae_5), np.mean(r2_5), num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 5\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy5.csv\", index=False)\n",
    "    break\n",
    "  \n",
    "print(f\"Model 5: Best params: {best_params_5} with MAE: {np.mean(best_mae_5)}, R2-score: {np.mean(best_r2_5)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_pit_samples=50, take_num_samples_when_full=0, normal_backtransform=True, trainable_bandwidths=True\n",
      "mat1 and mat2 shapes cannot be multiplied (64x148 and 8x100)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_r2_6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy6.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel 6: Best params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params_6\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(best_mae_6)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43mbest_r2_6\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n\u001b[1;32m     38\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy6.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_r2_6' is not defined"
     ]
    }
   ],
   "source": [
    "result = np.array([\"mae\", \"r2\", \"num_pit_samples\", \"take_num_samples_when_full\", \"normal_backtransform\", \"trainable_bandwidths\", \"model_id\"])\n",
    "for params in product(*param_grid.values()):\n",
    "  num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths = params\n",
    " \n",
    "  print(f\"num_pit_samples={num_pit_samples}, take_num_samples_when_full={take_num_samples_when_full},\"+\n",
    "        f\" normal_backtransform={normal_backtransform}, trainable_bandwidths={trainable_bandwidths}\")\n",
    "\n",
    "  model6 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    BatchPitNorm1d(num_features=10, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "  model6.to(device=device)\n",
    "  \n",
    "  try:\n",
    "    mae_6, r2_6 = train_model(model6, 1, True)\n",
    "    if np.mean(mae_6) < np.mean(best_mae_6):\n",
    "      best_mae_6 = mae_6\n",
    "      best_r2_6 = r2_6\n",
    "      best_params_6 = params\n",
    "\n",
    "    values = np.array([mae_6, r2_6, num_pit_samples, take_num_samples_when_full, normal_backtransform, trainable_bandwidths, \"model 6\"])\n",
    "    result = np.vstack((result, values))\n",
    "  except Exception as e: \n",
    "    print(e)\n",
    "    df = pd.DataFrame(result)\n",
    "    df.to_csv(\"energy6.csv\", index=False)\n",
    "    break\n",
    "print(f\"Model 6: Best params: {best_params_6} with accuracy: {np.mean(best_mae_6)}, F1-score: {np.mean(best_r2_6)}\")\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"energy6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1))\n",
    "model1.to(device=device)\n",
    "\n",
    "r2Score1, MAE1 = train_model(model1, 5)\n",
    "plt.boxplot(r2Score1, labels=[\"Model 1\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean of all total energies: {np.mean(data[:, -1])}\")\n",
    "plt.boxplot(MAE1, labels=[\"Model 1\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1))\n",
    "model2.to(device=device)\n",
    "\n",
    "r2Score2, MAE2 = train_model(model2, 5)\n",
    "plt.boxplot(r2Score2, labels=[\"Model 2\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE2, labels=[\"Model 2\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    BatchPitNorm1d(num_features=80, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model4.to(device=device)\n",
    "\n",
    "r2Score4, MAE4 = train_model(model4, 5)\n",
    "plt.boxplot(r2Score4, labels=[\"Model 4\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE4, labels=[\"Model 4\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 50),\n",
    "    BatchPitNorm1d(num_features=50, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 80),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(80),\n",
    "    nn.Linear(80, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model5.to(device=device)\n",
    "\n",
    "r2Score5, MAE5 = train_model(model5, 5)\n",
    "plt.boxplot(r2Score5, labels=[\"Model 5\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(y))\n",
    "plt.boxplot(MAE5, labels=[\"Model 5\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = nn.Sequential(\n",
    "    nn.Linear(data.shape[1]-1, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10),\n",
    "    BatchPitNorm1d(num_features=10, num_pit_samples=num_pit_samples, take_num_samples_when_full=take_num_samples_when_full,\n",
    "                    normal_backtransform=normal_backtransform, trainable_bandwidths=trainable_bandwidths, bw_select = \"RuleOfThumb\", dev=device),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1))\n",
    "model6.to(device=device)\n",
    "\n",
    "r2Score6, MAE6 = train_model(model6, 5)\n",
    "plt.boxplot(r2Score6, labels=[\"Model 6\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean of all total energies: \", np.mean(data[:, -1]))\n",
    "plt.boxplot(MAE6, labels=[\"Model 6\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([r2Score1, r2Score2, r2Score4, r2Score5, r2Score6], labels=[\"No bn/pit\", \"No pit\", \"Model 3\", \"Model 4\", \"model 6\"])\n",
    "plt.title(\"R2-score\")\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot([MAE1, MAE2, MAE4, MAE5, MAE6], labels=[\"No bn/pit\", \"No pit\", \"Model 4\", \"Model 5\", \"model 6\"])\n",
    "plt.title(\"Mean absolute error\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
